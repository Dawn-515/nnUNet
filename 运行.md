# nnunet

## 1 运行环境

```bash
# 创建环境
conda create -n nnunet python=3.11
conda activate nnunet
# 安装依赖
# 方法一，分别安装
conda install cuda=12.4
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia
# 方法二，pytorch-cuda=12.4会安装cuda以及对应的驱动
conda install pytorch pytorch-cuda=12.4 -c pytorch -c nvidia

python -c "
import torch; 
print('CUDA可用: ', torch.cuda.is_available()); 
print('CUDA版本: ', torch.version.cuda);
print('cuDNN版本:', torch.backends.cudnn.version())
"
```

## 2 nnunet

```bash
pip install nnunetv2
pip install hiddenlayer # 可选

# 设置永久环境变量
setx nnUNet_raw "E:\Workplace\github\nnUNet\data\nnUNet_raw"
setx nnUNet_preprocessed "E:\Workplace\github\nnUNet\data\nnUNet_preprocessed" 
setx nnUNet_results "E:\Workplace\github\nnUNet\data\nnUNet_results"
setx nnUNet_n_proc_DA "10"

# 查看环境变量
$env:nnUNet_n_proc_DA
# 或者使用Get-ChildItem查看所有环境变量
Get-ChildItem env:nnUNet*

# 删除环境变量
[Environment]::SetEnvironmentVariable("nnUNet_raw", $null, "User")
[Environment]::SetEnvironmentVariable("nnUNet_preprocessed", $null, "User")
[Environment]::SetEnvironmentVariable("nnUNet_results", $null, "User")
[Environment]::SetEnvironmentVariable("nnUNet_n_proc_DA", $null, "User")
```

```bash
dir D:\DE\Python\miniconda3\envs\nnunet\Scripts\nnUNetv2*
# 结果
nnUNetv2_accumulate_crossval_results.exe
nnUNetv2_apply_postprocessing.exe
nnUNetv2_convert_MSD_dataset.exe
nnUNetv2_convert_old_nnUNet_dataset.exe
nnUNetv2_determine_postprocessing.exe
nnUNetv2_download_pretrained_model_by_url.exe
nnUNetv2_ensemble.exe
nnUNetv2_evaluate_folder.exe
nnUNetv2_evaluate_simple.exe
nnUNetv2_export_model_to_zip.exe
nnUNetv2_extract_fingerprint.exe
nnUNetv2_find_best_configuration.exe
nnUNetv2_install_pretrained_model_from_zip.exe
nnUNetv2_move_plans_between_datasets.exe
nnUNetv2_plan_and_preprocess.exe
nnUNetv2_plan_experiment.exe
nnUNetv2_plot_overlay_pngs.exe
nnUNetv2_predict_from_modelfolder.exe # 从指定模型文件夹加载模型进行预测
nnUNetv2_predict.exe     # 使用训练好的模型进行预测                             
nnUNetv2_preprocess.exe
nnUNetv2_train.exe

```

### 2.1 nnUNet工具集功能介绍

nnUNet是一个自动化医学图像分割框架，以下是每个可执行文件的主要功能：

#### 2.1.1数据准备与预处理

##### 数据集转换

nnUNetv2_convert_MSD_dataset.exe - 将Medical Segmentation Decathlon数据集转换为nnUNet格式
nnUNetv2_convert_old_nnUNet_dataset.exe - 将旧版nnUNet数据集转换为v2格式

##### 预处理

nnUNetv2_plan_and_preprocess.exe - 一键完成数据分析和预处理

nnUNetv2_plan_experiment.exe - 分析数据集并创建训练计划
nnUNetv2_preprocess.exe - 单独执行数据预处理步骤

#### 2.1.2模型训练与评估

##### 模型训练

nnUNetv2_train.exe - 训练nnUNet模型
nnUNetv2_extract_fingerprint.exe - 提取数据集特征指纹

##### 预测与推理

nnUNetv2_predict.exe - 使用训练好的模型进行预测
nnUNetv2_predict_from_modelfolder.exe - 从指定模型文件夹加载模型进行预测
nnUNetv2_ensemble.exe - 集成多个模型的预测结果

##### 评估与后处理

nnUNetv2_evaluate_folder.exe - 评估一个文件夹中的分割结果
nnUNetv2_evaluate_simple.exe - 简化版评估工具
nnUNetv2_determine_postprocessing.exe - 确定最佳的后处理策略
nnUNetv2_apply_postprocessing.exe - 应用后处理到预测结果
nnUNetv2_plot_overlay_pngs.exe - 生成预测结果与真实标签的叠加可视化图像

#### 2.1.3模型管理

nnUNetv2_find_best_configuration.exe - 寻找最佳模型配置
nnUNetv2_accumulate_crossval_results.exe - 合并多折交叉验证结果
nnUNetv2_export_model_to_zip.exe - 将模型导出为zip文件
nnUNetv2_download_pretrained_model_by_url.exe - 通过URL下载预训练模型
nnUNetv2_install_pretrained_model_from_zip.exe - 从zip文件安装预训练模型
nnUNetv2_move_plans_between_datasets.exe - 在不同数据集间转移训练计划
这些工具共同构成了nnUNet的完整工作流程，覆盖了医学图像分割任务的各个环节。

## 3 训练

### 3.1 数据集下载与格式转换

```bash
# 下载msd数据集，解压到 nnUNet_raw 目录下
# 转换格式
# 1. 原始格式 (输入格式): Medical Segmentation Decathlon (MSD) 格式
# 2. 转换后的格式 (输出格式): nnUNetV2 内部数据集格式
# 3. 原始文件名 : Task01_BrainTumour
# 4. 转换后的文件名 : Dataset001_BrainTumour
nnUNetv2_convert_MSD_dataset -i E:\Workplace\github\nnUNet\data\nnUNet_raw\Task01_BrainTumour
```

1. 原始格式 (输入格式): Medical Segmentation Decathlon (MSD) 格式

位于路径 Task01_BrainTumour 的数据应该遵循 MSD 数据集的标准结构。其主要特点包括：

一个根文件夹 (例如，Task01_BrainTumour)。
dataset.json: 一个 JSON 文件，描述了数据集的元数据，如：
name: 数据集名称。
description: 数据集描述。
modalities: 一个字典，描述了图像的模态 (例如，"0": "FLAIR", "1": "T1ce" 等)。
labels: 一个字典，描述了分割标签的含义 (例如，"0": "background", "1": "tumor core" 等)。
numTraining: 训练样本的数量。
training: 一个列表，包含训练样本的信息，每个样本通常有图像文件路径和标签文件路径。
test (可选): 一个列表，包含测试样本的图像文件路径。
imagesTr/: 包含训练图像的文件夹。图像文件通常是 NIfTI 格式 (.nii.gz)。对于多模态数据，一个病例的多个模态图像会以特定方式命名，例如 BRATS_001_0000.nii.gz, BRATS_001_0001.nii.gz (其中_0000, _0001 对应 dataset.json 中定义的模态)。
labelsTr/: 包含训练标签的文件夹。标签文件通常也是 NIfTI 格式 (.nii.gz)，例如 BRATS_001.nii.gz。
imagesTs/ (可选): 包含测试图像的文件夹，结构与 imagesTr/ 类似。
2. 转换后的格式 (输出格式): nnUNetV2 内部数据集格式

转换脚本执行后，会在您的 nnUNet_raw 目录 (根据您的设置是 nnUNet_raw) 下创建一个新的数据集文件夹。如果原始任务是 Task01_BrainTumour，并且没有指定覆盖 ID，那么新的文件夹通常会被命名为 Dataset001_BrainTumour。这个新文件夹将包含 nnUNetV2 所需的格式：

一个新的 dataset.json 文件：这个文件由 nnUNetV2 生成，包含了框架运行所需的特定信息，例如：
channel_names 或 modality: 明确指定每个通道的名称或模态。
labels: 标签的定义，通常从原始 dataset.json 继承但可能经过 nnUNet 的处理。
numTraining: 训练样本数量。
file_ending: 图像文件的扩展名 (通常是 .nii.gz)。
overwrite_image_reader_writer: 指定特定的图像读写器。
dataset_description, dataset_name, dataset_release, dataset_reference, license 等元数据。
imagesTr/: 包含训练图像。文件名格式通常是 CASE_IDENTIFIER_XXXX.nii.gz，其中 XXXX 是一个4位数的模态标识符 (例如 0000, 0001)。
labelsTr/: 包含训练标签。文件名格式通常是 CASE_IDENTIFIER.nii.gz。
imagesTs/ (可选): 包含测试图像，结构与 imagesTr/ 类似。
总结：

该命令读取 MSD 格式的数据，对其进行解析和必要的重组，然后生成一个符合 nnUNetV2 内部要求的新数据集结构，包括一个新的 dataset.json 文件和重新组织（如果需要）的图像与标签文件。这个转换过程是使用 nnUNetV2 处理新数据集的第一步。

### 3.2 数据规划和预处理(CPU任务)

```bash
nnUNetv2_plan_and_preprocess -d 1 --verify_dataset_integrity

####  主要输出  ###
# 1 Experiment planning...
# 2 Dropping 3d_lowres config because the image size difference to 3d_fullres is too small.
# 3 2D U-Net configuration:
# 4 3D fullres U-Net configuration:
# 5 Plans were saved to E:\Workplace\github\nnUNet\data\nnUNet_preprocessed\Dataset001_BrainTumour\nnUNetPlans.json   
# Preprocessing...
# Preprocessing dataset Dataset001_BrainTumour
# Configuration: 2d...
# Configuration: 3d_lowres...
# INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset001_BrainTumour. Skipping.
```

### 3.3 寻找最佳配置

```bash
nnUNetv2_find_best_configuration
```

### 3.4 模型训练(GPU任务)

```bash
nnUNetv2_train 1 2d 0
# 模型保存
E:\Workplace\github\nnUNet\data\nnUNet_results\Dataset001_BrainTumour\nnUNetTrainer__nnUNetPlans__2d\fold_0


####  主要输出  ###
############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################
Using device: cuda:0

2025-05-20 20:44:51.323587: do_dummy_2d_data_aug: False
2025-05-20 20:44:51.325586: Creating new 5-fold cross-validation split...
2025-05-20 20:44:51.341717: Desired fold for training: 0
2025-05-20 20:44:51.342715: This split has 387 training and 97 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}

These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}}

2025-05-20 20:45:04.516514: Unable to plot network architecture:
2025-05-20 20:45:04.517512: No module named 'hiddenlayer'
2025-05-20 20:45:04.575811:
2025-05-20 20:45:04.575811: Epoch 0
2025-05-20 20:45:04.577206: Current learning rate: 0.01

```

#### 3.3.1 训练参数

 nnUNetv2_train <Dataset_ID> <Configuration> <Fold_ID> [OPTIONS]

* <Dataset_ID>: 您的数据集 ID。根据您的情况，这应该是 1 (对应 Dataset001_BrainTumour)。
* <Configuration>: 您想要训练的模型配置。常见的配置有：  
2d  
3d_fullres  
3d_lowres (如果预处理阶段没有丢弃此配置)  
*3d_cascade_fullres (如果适用且已规划)
您可以在 nnUNetPlans.json 文件中查看为您的数据集生成了哪些配置。从您的输出看，至少有 2d 和 3d_fullres。
* <Fold_ID>: 交叉验证的折数。nnU-Net 默认进行 5 折交叉验证。您可以指定 0, 1, 2, 3, 4 来分别训练每一折，或者使用 all 来训练所有折（但这通常是按顺序一个接一个地训练，而不是并行）。通常，您会为每一折启动一个单独的训练进程。

#### 3.3.2 减少训练时间

nnU-Net v2 的训练时间主要通过以下方式管理：

1. **Early Stopping (自动早停)**:
    * 默认情况下，`nnUNetTrainer` 会训练最多1000个 epoch。
    * 训练过程中会持续监控验证集的性能。如果验证集性能在一定数量的 epoch 内（由训练器内部的 `patience` 参数决定）没有提升，训练会自动提前停止。这是减少不必要训练时间并防止过拟合的主要方式。
    * 因此，即使设置了较高的最大 epoch 数，实际训练通常会在此之前结束。

2. **仅训练部分交叉验证折数 (Folds)**:
    * 您可以选择只训练一个或几个交叉验证折数，而不是全部5折。例如，只训练第0折（通常用于快速获得模型或资源有限时）：

        ```bash
        nnUNetv2_train 1 2d 0
        ```

    * 这显著减少了获得初步模型所需的总时间。

3. **使用默认的混合精度训练**:
    * nnU-Net v2 的默认训练器会自动尝试使用混合精度训练（AMP），如果您的环境（PyTorch版本、CUDA、GPU）支持。这可以在对模型精度影响很小的前提下加速训练并减少显存使用。
    * 通常不需要手动通过命令行参数（如 `--fp16`，该参数在 `nnUNetv2_train` 中不存在）来启用它。

4. **（高级）创建自定义训练器以修改最大 Epoch 数**:
    * 如果必须严格限制最大 epoch 数（而不是依赖早停机制），标准方法是创建一个继承自 `nnUNetTrainer` 的自定义训练器类，在其中修改 `self.num_epochs` 的值（例如设置为200）。然后，在运行训练时通过 `-tr YourCustomTrainerName` 参数来使用这个自定义的训练器。这需要编写少量 Python 代码，并将该代码放置在 nnU-Net 可以导入的路径下。

**总结**：对于减少训练时间，最直接的方法是依赖 nnU-Net 内置的早停机制，并可以考虑只训练一个交叉验证折数以快速获得结果。之前提到的 `--num_epochs` 和 `--fp16` 这样的命令行标志不是 `nnUNetv2_train` 的标准参数。

## 4 预测

```bash
# 预测
nnUNetv2_predict 1 2d 0 --npz
```

## 自己数据

预处理管道

预处理管道将原始医学图像转换为适合神经网络训练的标准化输入。

DefaultPreprocessor （默认预处理器）

原始医学图像

Transpose
（轴重新排序）

裁剪
（删除零个区域）

归一化
（通道）

重新采样
（To Target Spacing）

预处理数据

关键的预处理步骤包括：

转置：将图像轴重新排序为标准化格式
裁剪：使用 删除不必要的零区域crop_to_nonzero
标准化：应用强度标准化，按通道自定义
重新采样：将体素间距调整为目标分辨率
该类编排整个管道，存储有关训练所必需的边界框和前景/背景区域的信息。DefaultPreprocessor

## 预训练模型

```bash
nnUNetv2_download_pretrained_model_by_url URL路径
nnUNetv2_install_pretrained_model_from_zip ZIP文件路径
```
